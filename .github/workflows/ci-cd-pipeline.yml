name: CI/CD Pipeline (Build -> Deploy)

on:
  push:
    tags:
      - 'v*' # Chạy khi đánh tag

permissions:
  contents: read
  packages: write # Cần quyền write để push ảnh, read để pull ảnh

jobs:
  # --- GIAI ĐOẠN 1: BUILD & PUSH (Chạy trên Github Cloud) ---
  build-and-push:
    name: Build & Push Docker
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Get Version
        id: get_version
        run: echo "VERSION=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # Build Gateway
      - name: Build & Push Gateway
        run: |
          OWNER_LC=$(echo "${{ github.repository_owner }}" | tr '[:upper:]' '[:lower:]')
          IMAGE_NAME=ghcr.io/$OWNER_LC/landslide-gateway
          TAG=${{ steps.get_version.outputs.VERSION }}
          
          cd gateway
          docker build -t $IMAGE_NAME:$TAG -t $IMAGE_NAME:latest .
          docker push $IMAGE_NAME:$TAG
          docker push $IMAGE_NAME:latest

      # Build Server
      - name: Build & Push Server
        run: |
          OWNER_LC=$(echo "${{ github.repository_owner }}" | tr '[:upper:]' '[:lower:]')
          IMAGE_NAME=ghcr.io/$OWNER_LC/landslide-server
          TAG=${{ steps.get_version.outputs.VERSION }}
          
          cd server
          docker build -t $IMAGE_NAME:$TAG -t $IMAGE_NAME:latest .
          docker push $IMAGE_NAME:$TAG
          docker push $IMAGE_NAME:latest

  # --- GIAI ĐOẠN 2: DEPLOY (Chạy trên Server thật) ---
  deploy:
    name: Deploy to Server
    needs: build-and-push # <--- CHÌA KHÓA Ở ĐÂY: Phải chờ thằng trên xong mới được chạy
    runs-on: self-hosted
    steps:
      - name: Clean Workspace (Fix Permission Issues)
        run: |
          echo "Cleaning workspace to fix permission issues..."
          WORKSPACE_DIR="${GITHUB_WORKSPACE:-$HOME/actions-runner/_work/landslide-monitoring/landslide-monitoring}"
          
          if [ -d "$WORKSPACE_DIR" ]; then
            echo "Workspace exists at: $WORKSPACE_DIR"
            echo "Removing files created by Docker containers (may require sudo)..."
            
            # Xóa các file log và data được tạo bởi containers
            sudo rm -rf "$WORKSPACE_DIR/gateway/mosquitto/log" 2>/dev/null || true
            sudo rm -rf "$WORKSPACE_DIR/gateway/mosquitto/data" 2>/dev/null || true
            sudo rm -rf "$WORKSPACE_DIR/server/spark/checkpoint" 2>/dev/null || true
            sudo rm -rf "$WORKSPACE_DIR/server/kafka/data" 2>/dev/null || true
            sudo rm -rf "$WORKSPACE_DIR/server/zookeeper/data" 2>/dev/null || true
            
            # Thay đổi ownership của toàn bộ workspace về user hiện tại
            echo "Changing ownership to current user..."
            sudo chown -R $(whoami):$(whoami) "$WORKSPACE_DIR" 2>/dev/null || true
            
            echo "Workspace cleanup completed!"
          else
            echo "Workspace does not exist yet, skipping cleanup."
          fi
      
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Get Version
        id: get_version
        run: echo "VERSION=${GITHUB_REF#refs/tags/}" >> $GITHUB_OUTPUT

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Deploy Steps
        run: |
          echo "Starting deploy version ${{ steps.get_version.outputs.VERSION }}..."
          
          # --- BƯỚC 1: DỌN DẸP TẤT CẢ CONTAINER CŨ ---
          echo "=========================================="
          echo "STEP 1: Cleaning up old containers..."
          echo "=========================================="
          
          # Xóa tất cả container liên quan để tránh conflict
          # Danh sách container cần xóa (dựa trên log thủ công của bạn)
          CONTAINERS_TO_REMOVE="mosquitto mqtt-bridge kafka spark-master spark-worker zookeeper"
          
          for container in $CONTAINERS_TO_REMOVE; do
            if docker ps -a --format '{{.Names}}' | grep -q "^${container}$"; then
              echo "Removing container: $container"
              docker rm -f "$container" 2>/dev/null || echo "  → Already removed or not found"
            else
              echo "Container $container does not exist, skipping..."
            fi
          done
          
          # Xóa network cũ nếu có
          docker network rm landslide_network 2>/dev/null || echo "Network already removed or not found"
          
          # Tạo shared network mới để gateway và server giao tiếp được
          echo ""
          echo "Creating shared Docker network..."
          docker network create landslide_network || echo "Network already exists (will use existing)"
          
          # Kiểm tra network đã tạo
          docker network ls | grep landslide_network
          
          echo ""
          echo "Cleanup completed!"
          echo ""
          
          # --- BƯỚC 2: DEPLOY GATEWAY (MOSQUITTO + MQTT-BRIDGE) ---
          echo "=========================================="
          echo "STEP 2: Deploying Gateway (Mosquitto + MQTT Bridge)..."
          echo "=========================================="
          
          cd gateway
          export COMPOSE_PROJECT_NAME=landslide_gateway
          
          # Tải image mới nhất của mqtt-bridge
          echo "Pulling latest gateway images..."
          docker-compose pull
          
          # Khởi động gateway services
          echo "Starting Gateway services..."
          docker-compose up -d
          
          # Đợi gateway khởi động
          echo "Waiting for Gateway to be ready..."
          sleep 10
          
          # Kiểm tra Gateway
          echo "Gateway containers:"
          docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep -E "(mosquitto|mqtt-bridge)" || echo "Warning: Gateway containers not found"
          echo ""
          
          # --- BƯỚC 3: DEPLOY SERVER (KAFKA + SPARK + ZOOKEEPER) ---
          echo "=========================================="
          echo "STEP 3: Deploying Server Stack (Kafka + Spark)..."
          echo "=========================================="
          
          cd ../server
          export APP_VERSION=${{ steps.get_version.outputs.VERSION }}
          export COMPOSE_PROJECT_NAME=landslide_server

          # Tải image mới nhất về
          echo "Pulling latest server images..."
          docker-compose pull
          
          # Up tất cả server containers
          echo "Starting Server services..."
          docker-compose up -d
          
          # Đợi containers khởi động ổn định
          echo "Waiting for Server services to be ready..."
          sleep 15
          
          # Kiểm tra trạng thái TẤT CẢ containers
          echo ""
          echo "=========================================="
          echo "ALL RUNNING CONTAINERS:"
          echo "=========================================="
          docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
          echo ""
          
          # --- BƯỚC 4: CHẠY SPARK JOB ---
          echo "=========================================="
          echo "STEP 4: Starting Spark Job..."
          echo "=========================================="
          
          # Chờ Spark Master sẵn sàng
          echo "Waiting for Spark Master to be ready..."
          for i in {1..30}; do
            if docker exec spark-master curl -s http://localhost:8080 > /dev/null 2>&1; then
              echo "Spark Master is ready!"
              break
            fi
            echo "  Waiting... ($i/30)"
            sleep 2
          done
          
          # Chờ Kafka sẵn sàng
          echo ""
          echo "Waiting for Kafka to be ready..."
          for i in {1..20}; do
            if docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092 > /dev/null 2>&1; then
              echo "Kafka is ready!"
              break
            fi
            echo "  Waiting... ($i/20)"
            sleep 3
          done
          
          # Kiểm tra MQTT Bridge đã kết nối Kafka chưa
          echo ""
          echo "Checking MQTT Bridge connection..."
          docker logs mqtt-bridge --tail 20 2>&1 | grep -i "kafka" || echo "MQTT Bridge logs not showing Kafka yet"
          
          # Xóa checkpoint cũ và output file cũ (tránh conflict)
          echo ""
          echo "Cleaning old Spark checkpoints and outputs..."
          docker exec spark-master rm -rf /app/spark_jobs/checkpoint 2>/dev/null || true
          docker exec spark-master rm -f /app/spark_jobs/spark_output.log 2>/dev/null || true
          
          # Chạy Spark job với output redirect vào file
          echo ""
          echo "Submitting Spark job with output redirection..."
          docker exec spark-master bash -c "nohup /opt/spark/bin/spark-submit \
            --master spark://spark-master:7077 \
            --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
            /app/spark_jobs/processor.py \
            > /app/spark_jobs/spark_output.log 2>&1 &"
          
          echo "Spark job submitted successfully!"
          echo "Output will be saved to: /app/spark_jobs/spark_output.log"
          echo ""
          
          # --- BƯỚC 5: ĐỢI DATA FLOW QUA HỆ THỐNG (5 PHÚT) ---
          echo "=========================================="
          echo "STEP 5: Waiting for Data Flow (5 minutes)..."
          echo "=========================================="
          echo "Pipeline: Edge -> MQTT -> Kafka -> Spark -> Batch Processing"
          echo ""
          
          # Đợi 5 phút để data flow qua toàn bộ pipeline
          WAIT_TIME=300
          echo "Waiting ${WAIT_TIME} seconds (5 minutes) for data to flow through the system..."
          
          # Hiển thị progress mỗi 30 giây và preview batch data
          for i in {1..10}; do
            ELAPSED=$((i * 30))
            REMAINING=$((WAIT_TIME - ELAPSED))
            echo "  [$(date +%H:%M:%S)] Progress: ${ELAPSED}s / ${WAIT_TIME}s (${REMAINING}s remaining...)"
            
            # Sau 60 giây, bắt đầu check xem có batch data chưa
            if [ $ELAPSED -ge 60 ]; then
              BATCH_COUNT=$(docker exec spark-master grep -c "Batch:" /app/spark_jobs/spark_output.log 2>/dev/null || echo "0")
              if [ "$BATCH_COUNT" != "0" ]; then
                echo "    -> Found $BATCH_COUNT batch(es) processed so far!"
              fi
            fi
            
            sleep 30
          done
          
          echo ""
          echo "Wait completed! Now collecting logs..."
          echo ""
          
          # --- BƯỚC 6: THU THẬP VÀ LƯU LOG ---
          echo "=========================================="
          echo "STEP 6: Collecting and Saving Logs..."
          echo "=========================================="
          
          # Tạo thư mục log
          LOG_DIR="$HOME/spark_logs"
          mkdir -p "$LOG_DIR"
          TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
          LOG_FILE="$LOG_DIR/spark_deployment_${TIMESTAMP}.log"
          
          echo "Saving comprehensive logs to: $LOG_FILE"
          
          {
            echo "=========================================="
            echo "LANDSLIDE MONITORING - DEPLOYMENT LOG"
            echo "=========================================="
            echo "Timestamp: $(date)"
            echo "Version: ${{ steps.get_version.outputs.VERSION }}"
            echo "Deployed by: CI/CD Pipeline"
            echo "=========================================="
            echo ""
            
            echo "=========================================="
            echo "CONTAINER STATUS (ALL)"
            echo "=========================================="
            docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" || echo "No containers found"
            echo ""
            
            echo "Specific services status:"
            echo "  Gateway:"
            docker ps --format "  - {{.Names}} [{{.Status}}]" | grep -E "(mosquitto|mqtt-bridge)" || echo "    No gateway containers"
            echo "  Server:"
            docker ps --format "  - {{.Names}} [{{.Status}}]" | grep -E "(kafka|zookeeper|spark)" || echo "    No server containers"
            echo ""
            
            echo "=========================================="
            echo "MOSQUITTO LOGS (Last 200 lines)"
            echo "=========================================="
            docker logs mosquitto --tail 200 2>&1 || echo "Mosquitto logs not available"
            echo ""
            
            echo "=========================================="
            echo "MQTT BRIDGE LOGS (Last 500 lines)"
            echo "=========================================="
            docker logs mqtt-bridge --tail 500 2>&1 || echo "MQTT Bridge logs not available"
            echo ""
            
            echo "=========================================="
            echo "KAFKA TOPICS & MESSAGES CHECK"
            echo "=========================================="
            echo "Available topics:"
            docker exec kafka kafka-topics --list --bootstrap-server localhost:9092 2>&1 || echo "Cannot list Kafka topics"
            echo ""
            echo "Sample messages from landslide_data topic (last 10):"
            docker exec kafka kafka-console-consumer \
              --bootstrap-server localhost:9092 \
              --topic landslide_data \
              --from-beginning \
              --max-messages 10 \
              --timeout-ms 5000 2>&1 || echo "No messages in Kafka yet"
            echo ""
            
            echo "=========================================="
            echo "SPARK MASTER LOGS (Last 1000 lines)"
            echo "=========================================="
            docker logs spark-master --tail 1000 2>&1
            echo ""
            
            echo "=========================================="
            echo "SPARK WORKER LOGS (Last 500 lines)"
            echo "=========================================="
            docker logs spark-worker --tail 500 2>&1 || echo "Worker logs not available"
            echo ""
            
            echo "=========================================="
            echo "SPARK BATCH PROCESSING DATA (ASCII TABLES)"
            echo "=========================================="
            echo "Reading batch processing results from output file..."
            echo ""
            
            # Đọc batch data từ spark_output.log
            if docker exec spark-master test -f /app/spark_jobs/spark_output.log; then
              echo "Output file found! Extracting batch data..."
              echo ""
              
              # Lấy tất cả batch data
              BATCH_DATA=$(docker exec spark-master cat /app/spark_jobs/spark_output.log 2>&1 | grep -B 3 -A 10 "Batch:" | head -1000)
              
              if [ -n "$BATCH_DATA" ]; then
                echo "SUCCESS! Found batch processing data:"
                echo "---"
                echo "$BATCH_DATA"
                echo "---"
                
                # Đếm số batch đã xử lý
                BATCH_COUNT=$(docker exec spark-master grep -c "Batch:" /app/spark_jobs/spark_output.log 2>/dev/null || echo "0")
                echo ""
                echo "Total batches processed: $BATCH_COUNT"
              else
                echo "WARNING: Output file exists but no batch data found yet."
                echo "Job may still be initializing. Showing last 50 lines:"
                echo "---"
                docker exec spark-master tail -50 /app/spark_jobs/spark_output.log 2>&1
                echo "---"
              fi
            else
              echo "WARNING: Spark output file not found at /app/spark_jobs/spark_output.log"
              echo "Possible reasons:"
              echo "  1. Spark job failed to start"
              echo "  2. Output redirection failed"
              echo ""
              echo "Checking Spark Master logs for errors:"
              docker logs spark-master --tail 100 2>&1 | grep -i "error\|exception" | head -20 || echo "No errors found"
            fi
            
            echo ""
            echo "=========================================="
            echo "END OF DEPLOYMENT LOG"
            echo "=========================================="
            echo "Generated at: $(date)"
            echo "Log file: $LOG_FILE"
            echo "Total log size: $(echo "$ALL_SPARK_LOGS" | wc -l) lines from Spark Master"
            echo ""
          } > "$LOG_FILE" 2>&1
          
          # Xác nhận file đã được tạo
          if [ -f "$LOG_FILE" ]; then
            echo ""
            echo "=========================================="
            echo "SUCCESS! Logs saved successfully"
            echo "=========================================="
            echo "File: $LOG_FILE"
            echo "Size: $(du -h "$LOG_FILE" | cut -f1)"
            echo "Path: $(realpath "$LOG_FILE")"
            echo ""
            ls -lh "$LOG_FILE"
            
            # Kiểm tra xem có batch data trong log không
            echo ""
            if grep -q "Batch:" "$LOG_FILE"; then
              echo "Status: BATCH DATA FOUND in log file!"
              echo ""
              echo "Preview of batch data (first occurrence):"
              echo "---"
              grep -A 10 "Batch:" "$LOG_FILE" | head -15
              echo "---"
            else
              echo "Status: No batch data found yet."
              echo "This may be normal if edge sensors are not sending data."
              echo ""
              echo "To verify deployment manually later, check:"
              echo "  1. Edge sensors running: docker ps (on edge devices)"
              echo "  2. Data in Kafka: docker exec kafka kafka-console-consumer ..."
              echo "  3. Spark processing: docker logs spark-master | grep Batch"
            fi
          else
            echo ""
            echo "WARNING: Log file was not created at $LOG_FILE"
            echo "Current directory: $(pwd)"
            echo "Log directory: $LOG_DIR (exists: $([ -d "$LOG_DIR" ] && echo 'Yes' || echo 'No'))"
          fi
          
          echo ""
          echo "=========================================="
          echo "DEPLOYMENT COMPLETED SUCCESSFULLY!"
          echo "=========================================="
          echo "Version: ${{ steps.get_version.outputs.VERSION }}"
          echo "Deployed at: $(date)"
          echo ""
          echo "Deployed Components:"
          echo ""
          echo "Gateway (Data Ingestion):"
          docker ps --format "  - {{.Names}} [{{.Status}}]" | grep -E "(mosquitto|mqtt-bridge)" || echo "  (none)"
          echo ""
          echo "Server (Data Processing):"
          docker ps --format "  - {{.Names}} [{{.Status}}]" | grep -E "(kafka|zookeeper|spark)" || echo "  (none)"
          echo ""
          echo "Total active containers:"
          docker ps --format "  - {{.Names}}" | wc -l
          echo ""
          echo "Next Steps:"
          echo "  1. Check log file: cat $LOG_FILE"
          echo "  2. Monitor Spark: docker logs -f spark-master"
          echo "  3. View Spark UI: http://server-ip:9090"
          echo ""
          echo "Deployment pipeline finished!"
      
      - name: Fix Permissions for Next Run
        if: always()
        run: |
          echo "=========================================="
          echo "Fixing file permissions for next deployment..."
          echo "=========================================="
          
          # Đặt lại ownership cho các thư mục được tạo bởi containers
          # Điều này đảm bảo lần deploy sau không gặp permission issues
          
          echo "Fixing gateway permissions..."
          sudo chown -R $(whoami):$(whoami) gateway/mosquitto 2>/dev/null || true
          
          echo "Fixing server permissions..."
          sudo chown -R $(whoami):$(whoami) server/spark 2>/dev/null || true
          sudo chown -R $(whoami):$(whoami) server/kafka 2>/dev/null || true
          sudo chown -R $(whoami):$(whoami) server/zookeeper 2>/dev/null || true
          
          echo "Permission fix completed!"
          echo ""

